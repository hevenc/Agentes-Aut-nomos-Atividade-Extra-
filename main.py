# --- Importar as bibliotecas --- #
import numpy as np
import pandas as pd
import altair as alt
import streamlit as st
import plotly.express as px
import matplotlib.pyplot as plt
import os
import io
from dotenv import load_dotenv

# --- Importa√ß√µes da LangChain e Google/Groq --- #
from langchain_groq import ChatGroq
from langchain.agents import Tool, AgentExecutor, create_react_agent
from langchain.globals import set_debug
from langchain_core.prompts import PromptTemplate
from langchain_experimental.tools import PythonAstREPLTool
from langchain_core.language_models.chat_models import BaseChatModel
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.memory import ConversationBufferMemory
from typing import Type

set_debug(False)  # Desativado para n√£o poluir o output no Streamlit

# Carrega as vari√°veis de ambiente do arquivo .env (arquivo com a chave de API)
load_dotenv()

# --- Configura√ß√µes iniciais --- #
st.set_page_config(
    page_title="DataPilot CSV",
    layout="wide",
    # Adicionando a configura√ß√£o de tema aqui:
    initial_sidebar_state="auto",
    menu_items=None,
    # Configurando o tema
    page_icon="ü§ñ"
)

# --- Estiliza√ß√£o do T√≠tulo  --- #
st.markdown(
    """
    <style>
    /* 1. Centraliza o T√≠tulo e o subt√≠tulo (H1, H2) em toda a aplica√ß√£o */
    div.stApp > header {
        text-align: center;
    }

    /* 2. Estiliza a cor e o tamanho do H1 (o t√≠tulo principal) */
    h1 {
        color: #9933FF; /* Roxo Profundo */
        font-size: 2.5em; 
        text-align: center; /* Centraliza o texto dentro do H1 */
    }

    /* 3. Centraliza a div que cont√©m o t√≠tulo  */
    [data-testid="stAppViewContainer"] > div > section > div {
        display: flex;
        flex-direction: column;
        align-items: center;
    }
    </style>
    """,
    unsafe_allow_html=True
)

st.title('DataPilot CSV')


# --- Fun√ß√µes Auxiliares para Gr√°ficos --- #

# Esta fun√ß√£o permite que o agente Python gere c√≥digo de plotagem e a captura (e exibi√ß√£o) no Streamlit.
# O c√≥digo gerado pelo agente DEVE usar `st_plot_capture()`
def st_plot_capture(plot_type, code_to_exec):
    """Executa o c√≥digo de plotagem e exibe o gr√°fico no Streamlit."""
    try:
        # Cria um buffer para capturar a sa√≠da padr√£o
        buffer = io.StringIO()

        # Executa o c√≥digo Python
        exec(code_to_exec, {'df': st.session_state.df_upload,
                            'px': px,
                            'plt': plt,
                            'st': st,
                            'st_plot_capture': st_plot_capture,
                            'np': np,
                            'pd': pd},
             {'output_buffer': buffer})

        # Captura o gr√°fico, se for Matplotlib (plt)
        if plot_type == 'matplotlib':
            fig = plt.gcf()
            st.pyplot(fig)
            plt.close(fig)

        # Captura o gr√°fico, se for Plotly (px)
        elif plot_type == 'plotly':
            # O c√≥digo Plotly deve criar uma vari√°vel `fig` e usar `st.plotly_chart(fig)`
            # ou simplesmente ser um c√≥digo Plotly que o LLM sabe renderizar.
            pass  # A execu√ß√£o direta no `exec` j√° deve ter chamado st.plotly_chart()

        return f"Gr√°fico do tipo {plot_type} gerado e exibido com sucesso."

    except Exception as e:
        return f"Erro ao gerar o gr√°fico: {e}. Verifique se o c√≥digo gerado est√° correto."


# --- Classe do Agente --- #
class AgenteDataFrame:
    def __init__(self, llm: Type[BaseChatModel], df: pd.DataFrame, memory: ConversationBufferMemory) -> None:
        self.__df = df
        self.__llm = llm
        self.__memory = memory  # Adicionando mem√≥ria (obrigat√≥ria na atividade)

    @property
    def ferramentas(self):
        # A ferramenta Python agora tem acesso √†s bibliotecas de plotagem e √† fun√ß√£o de captura
        python_globals = {
            "df": self.__df,
            "px": px,
            "plt": plt,
            "np": np,
            "pd": pd,
            "st": st,  # Dando acesso ao Streamlit para exibir gr√°ficos Plotly/Matplotlib
        }

        # Ferramenta para execu√ß√£o de c√≥digo Python com acesso ao DataFrame (df)
        python_tool = PythonAstREPLTool(
            locals=python_globals,
            name="C√≥digos Python para An√°lise e Gr√°ficos",
            description="""
            Utilize esta ferramenta sempre que o usu√°rio solicitar c√°lculos, consultas, transforma√ß√µes ou GERA√á√ÉO DE GR√ÅFICOS
            (histogramas, boxplots, dispers√£o, barras, etc.).
            Use Plotly Express (px) para gr√°ficos interativos. Ex: `fig = px.histogram(df, x='coluna'); st.plotly_chart(fig)`.
            Use Matplotlib (plt) para gr√°ficos est√°ticos. Ex: `plt.figure(figsize=(10,5)); plt.hist(df['coluna']); st.pyplot()`.
            Retorne SEMPRE a resposta final em portugu√™s ap√≥s a an√°lise.
            """
        )

        return [python_tool]

    @property
    def react_prompt(self):
        # Cria um buffer para capturar a sa√≠da de df.info()
        info_buffer = io.StringIO()

        # Chama df.info() e direciona sua sa√≠da para o buffer
        # df.info() retorna None, mas preenche info_buffer
        self.__df.info(buf=info_buffer)

        # Concatena o head formatado com o conte√∫do capturado do buffer
        df_info = self.__df.head().to_markdown() + "\n\n" + info_buffer.getvalue()

        return PromptTemplate(
            input_variables=["input", "agent_scratchpad", "tools", "tool_names", "history"],
            partial_variables={"df_info": df_info},
            template="""
            Voc√™ √© um assistente de An√°lise Explorat√≥ria de Dados (EDA) que responde SEMPRE em portugu√™s.

            Voc√™ tem acesso a um DataFrame pandas chamado `df`.
            Aqui est√£o as primeiras linhas e a descri√ß√£o dos tipos de dados do DataFrame:
            {df_info}

            Seu objetivo principal √© responder perguntas do usu√°rio, gerar gr√°ficos (usando Plotly/Matplotlib e fun√ß√µes st.plotly_chart/st.pyplot) 
            e, CRITICAMENTE, fornecer uma se√ß√£o de **CONCLUS√ïES** ap√≥s a an√°lise.
            As conclus√µes devem resumir os achados e implica√ß√µes do que foi analisado, utilizando seu hist√≥rico de conversas.

            Hist√≥rico da Conversa:
            {history}

            Ferramentas dispon√≠veis:
            {tools}

            Use o seguinte formato de racioc√≠nio ReAct:

            Question: pergunta do usu√°rio
            Thought: racioc√≠nio do que fazer (sempre em portugu√™s)
            Action: nome da ferramenta, uma das [{tool_names}]
            Action Input: entrada para a a√ß√£o (c√≥digo Python)
            Observation: resultado da a√ß√£o
            ...(repita Thought/Action/... quantas vezes quiser)
            Thought: Agora eu sei a resposta final e as conclus√µes a tirar
            Final Answer: Resposta completa, incluindo gr√°ficos gerados, resultados e, o mais importante, uma se√ß√£o clara de **CONCLUS√ïES:**

            Comece!

            Question: {input}
            Thought: {agent_scratchpad}
            """
        )

    def executar(self, pergunta: str) -> str:
        agente = create_react_agent(llm=self.__llm, tools=self.ferramentas, prompt=self.react_prompt)
        # O executor agora recebe a mem√≥ria
        executor = AgentExecutor(
            agent=agente,
            tools=self.ferramentas,
            handle_parsing_errors=True,
            memory=self.__memory,
            verbose=True,  # Para ver o ReAct completo
            max_iterations=100,
            max_execution_time=300.0
        )
        # A mem√≥ria √© passada como parte do invoke, e o executor a gerencia
        resposta = executor.invoke({"input": pergunta})
        return resposta["output"]


# --- Layout Streamlit --- #
col1, col2 = st.columns([1, 4])

with col1:
    upload = st.file_uploader("", type="csv")

    # Inicializa ou carrega o DataFrame e o Hist√≥rico de Chat
    if 'df_upload' not in st.session_state:
        st.session_state.df_upload = None
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    if 'memory' not in st.session_state:
        st.session_state.memory = ConversationBufferMemory(memory_key="history", return_messages=False)

    if upload is not None and st.session_state.df_upload is None or (
            upload is not None and upload.name != st.session_state.upload_name):
        try:
            df_upload = pd.read_csv(upload)
            st.session_state.df_upload = df_upload
            st.session_state.upload_name = upload.name

            # Resetar o hist√≥rico e a mem√≥ria ao carregar um novo arquivo
            st.session_state.chat_history = []
            st.session_state.memory = ConversationBufferMemory(memory_key="history", return_messages=False)

            st.success(f"Arquivo **{upload.name}** carregado com sucesso!")
        except Exception as e:
            st.error(f"Erro ao carregar o CSV: {e}")
            st.session_state.df_upload = None

    if st.session_state.df_upload is not None:
        st.write(f"üßæ Primeiras linhas do arquivo: **{st.session_state.upload_name}**")
        st.dataframe(st.session_state.df_upload.head())

with col2:
    st.subheader("ü§ñ Converse com a IA")

    # Exibe hist√≥rico do chat (Com Destaque para Conclus√µes)
    for msg in st.session_state.chat_history:
        with st.chat_message(msg["role"]):
            conteudo = msg["content"]
            # Verifica se h√° a se√ß√£o de conclus√µes (o agente usa negrito **)
            if "**CONCLUS√ïES:**" in conteudo:
                # Separa o conte√∫do principal das conclus√µes
                partes = conteudo.split("**CONCLUS√ïES:**", 1)
                st.markdown(partes[0])  # Conte√∫do principal e racioc√≠nio

                # Exibe as Conclus√µes em um bloco de destaque (st.info)
                st.info(f"**CONCLUS√ïES:**{partes[1]}")
            else:
                st.markdown(conteudo)

    user_input = st.chat_input("Digite sua pergunta...")

    # Tenta pegar a chave da vari√°vel de ambiente
    google_api_key = os.getenv("GOOGLE_API_KEY", "")

    if not google_api_key:
        st.warning("‚ö†Ô∏è Chave de API do Gemini n√£o encontrada. Por favor, defina a vari√°vel de ambiente GOOGLE_API_KEY.")

    # Instancia LLM Gemini (somente se a chave existir)
    if google_api_key:
        llm = ChatGoogleGenerativeAI(
            model="gemini-2.5-flash-preview-05-20",
            google_api_key=google_api_key
        )
    else:
        llm = None

    if user_input and st.session_state.df_upload is not None and llm is not None:
        # Salva pergunta no hist√≥rico
        st.session_state.chat_history.append({"role": "user", "content": user_input})

        # Exibe a pergunta na interface
        with st.chat_message("user"):
            st.markdown(user_input)

        # Cria o agente com df e mem√≥ria
        agente = AgenteDataFrame(llm=llm, df=st.session_state.df_upload, memory=st.session_state.memory)

        with st.spinner("Pensando e analisando..."):
            # O executor gerencia a mem√≥ria internamente
            resposta = agente.executar(user_input)

            # Salva resposta no hist√≥rico
            st.session_state.chat_history.append({"role": "assistant", "content": resposta})

            # Exibe resposta (Com Destaque para Conclus√µes)
            with st.chat_message("assistant"):
                # Aplica o mesmo destaque de CONCLUS√ïES
                if "**CONCLUS√ïES:**" in resposta:
                    partes = resposta.split("**CONCLUS√ïES:**", 1)
                    st.markdown(partes[0])
                    st.info(f"**CONCLUS√ïES:**{partes[1]}")
                else:
                    st.markdown(resposta)

    elif user_input and st.session_state.df_upload is None:
        st.warning("‚ö†Ô∏è Por favor, envie um CSV em **Browse files**, antes de fazer perguntas.")








